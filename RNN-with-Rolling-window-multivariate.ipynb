{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Recurrent Neural Network Projects\n",
    "\n",
    "Welcome to the Recurrent Neural Network Project in the Artificial Intelligence Nanodegree! In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.  \n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation TODOs in this notebook\n",
    "\n",
    "This notebook contains two problems, cut into a variety of TODOs.  Make sure to complete each section containing a TODO marker throughout the notebook.  For convenience we provide links to each of these sections below.\n",
    "\n",
    "[TODO #1: Implement a function to window time series](#TODO_1)\n",
    "\n",
    "[TODO #2: Create a simple RNN model using keras to perform regression](#TODO_2)\n",
    "\n",
    "[TODO #3: Finish cleaning a large text corpus](#TODO_3)\n",
    "\n",
    "[TODO #4: Implement a function to window a large text corpus](#TODO_4)\n",
    "\n",
    "[TODO #5: Create a simple RNN model using keras to perform multiclass classification](#TODO_5)\n",
    "\n",
    "[TODO #6: Generate text using a fully trained RNN model and a variety of input sequences](#TODO_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Perform time series prediction \n",
    "\n",
    "In this project you will perform time series prediction using a Recurrent Neural Network regressor.  In particular you will re-create the figure shown in the notes - where the stock price of Apple was forecasted (or predicted) 7 days in advance.  In completing this exercise you will learn how to construct RNNs using Keras, which will also aid in completing the second project in this notebook.\n",
    "\n",
    "The particular network architecture we will employ for our RNN is known as  [Long Term Short Memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory), which helps significantly avoid technical problems with optimization of RNNs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting started\n",
    "\n",
    "First we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.\n",
    "\n",
    "Here we normalize the series to lie in the range [0,1] [using this scikit function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), but it is also commonplace to normalize by a series standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (2.16.2)\n",
      "Requirement already satisfied: tf-keras==2.16 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (2.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (3.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (0.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (1.23.5)\n",
      "Requirement already satisfied: setuptools in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (65.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (4.25.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (4.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (3.5.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (3.11.0)\n",
      "Requirement already satisfied: packaging in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (23.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (2.28.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (1.66.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (24.3.25)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow==2.16.2) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.37.1)\n",
      "Requirement already satisfied: optree in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.12.1)\n",
      "Requirement already satisfied: namex in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.0.8)\n",
      "Requirement already satisfied: rich in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (13.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.16.2 tf-keras==2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "import keras\n",
    "import string\n",
    "\n",
    "\n",
    "# Done: fill out the function below that transforms the input series \n",
    "# and window-size into a set of input/output pairs for use with our RNN model\n",
    "''' ******************************************************** '''\n",
    "def window_transform_series(series, window_size):\n",
    "    # containers for input/output pairs\n",
    "    X,y = [],[]\n",
    "        \n",
    "    for idx in range(len(series)-window_size):\n",
    "        X.append(series[idx:idx+window_size])\n",
    "    \n",
    "    y = series[window_size:]\n",
    "    \n",
    "    # reshape each \n",
    "    X = np.asarray(X)\n",
    "    X.shape = (np.shape(X)[0:2])\n",
    "    y = np.asarray(y)\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "''' ******************************************************** '''\n",
    "# Done: build an RNN to perform regression on our time series input/output data\n",
    "def build_part1_RNN(window_size):\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(LSTM(5, input_shape=(window_size, 1)))\n",
    "    RNN_model.add(Dense(1))\n",
    "    return RNN_model\n",
    "    #pass\n",
    "\n",
    "\n",
    "''' ******************************************************** '''\n",
    "### Done: return the text input with only ascii lowercase and the punctuation \n",
    "#   given below included.\n",
    "def cleaned_text(text):\n",
    "    punctuation = ['!', ',', '.', ':', ';', '?']\n",
    "    extra1=['\\xa0', '¢', '¨', '©', 'ã']\n",
    "    extra2=['à', 'â', 'è', 'é']\n",
    "    remove_set=(set(string.printable) | set(extra1) |set(extra2))-(set(string.ascii_lowercase)| set(punctuation) |set(' '))\n",
    "    remove_set=list(remove_set)\n",
    "    for c in remove_set:\n",
    "        text=text.replace(c,' ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "''' ******************************************************** '''\n",
    "### Done: fill out the function below that transforms the input text and \n",
    "##  window-size into a set of input/output pairs for use with our RNN model\n",
    "\n",
    "def window_transform_text(text, window_size, step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    idx = 0\n",
    "    \n",
    "    while idx<(len(text)-window_size):\n",
    "        inputs.append(text[idx:idx+window_size])\n",
    "        outputs.append(text[idx+window_size])\n",
    "        idx += step_size\n",
    "    \n",
    "      \n",
    "    # reshape each \n",
    "    '''\n",
    "    inputs = np.asarray(inputs)\n",
    "    inputs.shape = (len(inputs),1)\n",
    "    outputs = np.asarray(outputs)\n",
    "    outputs.shape = (len(outputs),1)\n",
    "    '''\n",
    "    \n",
    "    return inputs,outputs\n",
    "\n",
    "''' ******************************************************** '''\n",
    "# TODO build the required RNN model: \n",
    "# a single LSTM hidden layer with softmax activation, categorical_crossentropy loss \n",
    "def build_part2_RNN(window_size, num_chars):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(window_size, num_chars)))\n",
    "    model.add(Dense(num_chars))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling function for the dataset\n",
    "def scale_data(df, target_column):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(df_scaled, columns=df.columns), scaler\n",
    "\n",
    "# Inverse scaling for predictions\n",
    "def inverse_scale(scaler, predictions, target_index):\n",
    "    # Inverse scale only the target column\n",
    "    full_scaled = np.zeros((len(predictions), scaler.n_features_in_))\n",
    "    full_scaled[:, target_index] = predictions\n",
    "    return scaler.inverse_transform(full_scaled)[:, target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%load_ext autoreload\\n%autoreload 2\\n\\nfrom my_answers import *\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load in necessary libraries for data input and normalization\n",
    "# Wi th inline backend, the output of plotting commands is displayed inline \n",
    "# within frontends directly below the code cell that produced it.\n",
    "# The resulting plots will then also be stored in the notebook document.\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %autoreload-reload all modules (except those excluded by %aimport) automatically now.\n",
    "# %autoreload 2 - Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from my_answers import *\n",
    "\n",
    "'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the (normalized) time series we'll be performing predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>1949</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>1949</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>1949</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Passengers  year  month\n",
       "0  1949-01         112  1949      1\n",
       "1  1949-02         118  1949      2\n",
       "2  1949-03         132  1949      3\n",
       "3  1949-04         129  1949      4\n",
       "4  1949-05         121  1949      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "airpass = pd.read_csv('AirPassengers.csv')\n",
    "airpass['year'] = airpass['Month'].apply(lambda x: int(x[:4]))\n",
    "airpass['month'] = airpass['Month'].apply(lambda x: int(x[5:]))\n",
    "airpass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month         object\n",
       "Passengers     int64\n",
       "year           int64\n",
       "month          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpass.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Cutting our time series into sequences\n",
    "\n",
    "Remember, our time series is a sequence of numbers that we can represent in general mathematically as \n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below.\n",
    "\n",
    "<img src=\"timeseries_windowing_training.gif\" width=600 height=600/>\n",
    "\n",
    "For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of length 5 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpass = airpass[['Passengers','year','month']]\n",
    "airpass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "target_column = 'Passengers'\n",
    "df_scaled, scaler = scale_data(airpass, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (134, 10, 3)\n",
      "Output shape (y): (134, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_rnn_data(df, input_window, output_window, target_columns=None):\n",
    "    \"\"\"\n",
    "    Prepares multivariate time series data for RNN processing using a rolling window approach.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The multivariate time series as a pandas DataFrame.\n",
    "        input_window (int): Number of time steps used as input (X).\n",
    "        output_window (int): Number of time steps used as output (y).\n",
    "        target_columns (list): Optional list of target columns. If None, uses all columns.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Input sequences of shape (num_samples, input_window, num_features).\n",
    "        y (np.array): Output labels of shape (num_samples, output_window, num_features).\n",
    "    \"\"\"\n",
    "    \n",
    "    if target_columns is None:\n",
    "        target_columns = df.columns  # Use all columns if target_columns is not provided\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(df) - input_window - output_window + 1):\n",
    "        # Get the input window (X) and the corresponding output window (y)\n",
    "        X.append(df.iloc[i:i+input_window].values)\n",
    "        y.append(df.iloc[i+input_window:i+input_window+output_window][target_columns].values)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "input_window = 10\n",
    "output_window = 1\n",
    "X, y = prepare_rnn_data(df_scaled, input_window, output_window, target_columns=['Passengers'])\n",
    "\n",
    "print(\"Input shape (X):\", X.shape)\n",
    "print(\"Output shape (y):\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Splitting into training and testing sets\n",
    "\n",
    "In order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.\n",
    "\n",
    "Note how here we are **not** splitting the dataset *randomly* as one typically would do when validating a regression model.  This is because our input/output pairs *are related temporally*.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points *within the timeframe of our training set*.  \n",
    "\n",
    "We want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict *future* values of a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split our dataset into training / testing sets\n",
    "train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "\n",
    "# partition the training set\n",
    "X_train = X[:train_test_split,:]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "# keep the last chunk for testing\n",
    "X_test = X[train_test_split:,:]\n",
    "y_test = y[train_test_split:]\n",
    "train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_2'></a>\n",
    "\n",
    "## 1.4  Build and run an RNN regression model\n",
    "\n",
    "Having created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications\n",
    "\n",
    "- layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))\n",
    "- layer 2 uses a fully connected module with one unit\n",
    "- the 'mean_squared_error' loss should be used (remember: we are performing regression here)\n",
    "\n",
    "This can be constructed using just a few lines - see e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LSTM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) \n",
    "\n",
    "(given in the cell below).  (remember to copy your completed function into the script *my_answers.py* function titled *build_part1_RNN* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01544402, 0.        , 0.        ],\n",
       "        [0.02702703, 0.        , 0.09090909],\n",
       "        [0.05405405, 0.        , 0.18181818],\n",
       "        ...,\n",
       "        [0.08494208, 0.        , 0.63636364],\n",
       "        [0.06177606, 0.        , 0.72727273],\n",
       "        [0.02895753, 0.        , 0.81818182]],\n",
       "\n",
       "       [[0.02702703, 0.        , 0.09090909],\n",
       "        [0.05405405, 0.        , 0.18181818],\n",
       "        [0.04826255, 0.        , 0.27272727],\n",
       "        ...,\n",
       "        [0.06177606, 0.        , 0.72727273],\n",
       "        [0.02895753, 0.        , 0.81818182],\n",
       "        [0.        , 0.        , 0.90909091]],\n",
       "\n",
       "       [[0.05405405, 0.        , 0.18181818],\n",
       "        [0.04826255, 0.        , 0.27272727],\n",
       "        [0.03281853, 0.        , 0.36363636],\n",
       "        ...,\n",
       "        [0.02895753, 0.        , 0.81818182],\n",
       "        [0.        , 0.        , 0.90909091],\n",
       "        [0.02702703, 0.        , 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.58108108, 0.90909091, 1.        ],\n",
       "        [0.6042471 , 1.        , 0.        ],\n",
       "        [0.55405405, 1.        , 0.09090909],\n",
       "        ...,\n",
       "        [1.        , 1.        , 0.54545455],\n",
       "        [0.96911197, 1.        , 0.63636364],\n",
       "        [0.77992278, 1.        , 0.72727273]],\n",
       "\n",
       "       [[0.6042471 , 1.        , 0.        ],\n",
       "        [0.55405405, 1.        , 0.09090909],\n",
       "        [0.60810811, 1.        , 0.18181818],\n",
       "        ...,\n",
       "        [0.96911197, 1.        , 0.63636364],\n",
       "        [0.77992278, 1.        , 0.72727273],\n",
       "        [0.68918919, 1.        , 0.81818182]],\n",
       "\n",
       "       [[0.55405405, 1.        , 0.09090909],\n",
       "        [0.60810811, 1.        , 0.18181818],\n",
       "        [0.68918919, 1.        , 0.27272727],\n",
       "        ...,\n",
       "        [0.77992278, 1.        , 0.72727273],\n",
       "        [0.68918919, 1.        , 0.81818182],\n",
       "        [0.55212355, 1.        , 0.90909091]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.initializers import HeNormal\n",
    "def build_part3_RNN(window_size):\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(Input(shape=np.shape(X)[1:]))\n",
    "    RNN_model.add(LSTM(50,activation='relu',return_sequences=True,kernel_regularizer=l2(0.001), kernel_initializer=HeNormal())) #,dropout=Float('droput',min_value=0.15, max_value=0.99, step=0.05)))\n",
    "    #RNN_model.add(Dropout(0.1))\n",
    "    RNN_model.add(LSTM(50,activation='relu',return_sequences=True, kernel_regularizer=l2(0.001), kernel_initializer=HeNormal()))\n",
    "    RNN_model.add(LSTM(10,activation='relu',return_sequences=True, kernel_regularizer=l2(0.001), kernel_initializer=HeNormal()))\n",
    "    RNN_model.add(Dense(1))\n",
    "    return RNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattsalomon/miniconda3/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Done: create required RNN model\n",
    "# import keras network libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow.keras\n",
    "\n",
    "# given - fix random seed - so we can all reproduce the same results on our default time series\n",
    "np.random.seed(0)\n",
    "\n",
    "window_size = 10\n",
    "# TODO: implement build_part1_RNN in my_answers.py\n",
    "#from my_answers import build_part1_RNN\n",
    "model = build_part3_RNN(window_size)\n",
    "\n",
    "# build model using keras documentation recommended optimizer initialization\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your model built you can now fit the model by activating the cell below!  Note: the number of epochs (np_epochs) and batch_size are preset (so we can all produce the same results).  You can choose to toggle the verbose parameter - which gives you regular updates on the progress of the algorithm - on and off by setting it to 1 or 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34f4a31f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run your model!\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Checking model performance\n",
    "\n",
    "With your model fit we can now make predictions on both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "def prepare_forecat_data(df, input_window, output_window, target):\n",
    "    \"\"\"\n",
    "    Prepares multivariate time series data for RNN processing using a rolling window approach.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The multivariate time series as a pandas DataFrame.\n",
    "        input_window (int): Number of time steps used as input (X).\n",
    "        output_window (int): Number of time steps used as output (y).\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Input sequences of shape (num_samples, input_window, num_features).\n",
    "    \"\"\"\n",
    "    \n",
    "#     if target_columns is None:\n",
    "#         target_columns = df.columns  # Use all columns if target_columns is not provided\n",
    "    \n",
    "    exogenous, data = [], []\n",
    "    \n",
    "    for i in range(len(df) - input_window - output_window + 1):\n",
    "        exogenous.append(df[[x for x in df.columns if x!=target]].iloc[i:i+input_window].values)\n",
    "        #data.append(df[[x for x in df.columns if x==target ]].iloc[i:i+input_window].values)\n",
    "        data.append(df.iloc[i:i+input_window][target].values)\n",
    "    return np.array(data), np.array(exogenous)\n",
    "\n",
    "def rolling_window_prediction(model, data, exogenous_inputs,df_scaled, window_size, forecast_steps=1):\n",
    "    \"\"\"\n",
    "    Generates rolling window time series predictions using a pre-trained LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Pre-trained TensorFlow model (LSTM).\n",
    "        data: numpy array of the main time series data (shape: [n_samples, n_features]).\n",
    "        exogenous_inputs: numpy array of exogenous inputs (shape: [n_samples, n_exogenous_features]).\n",
    "        window_size: Size of the rolling window.\n",
    "        forecast_steps: Number of time steps to predict at each iteration.\n",
    "    \n",
    "    Returns:\n",
    "        predictions: List of predicted values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to store predictions\n",
    "    predictions = []\n",
    "    data = np.expand_dims(data, axis=-1) \n",
    "    # Combine time series data and exogenous inputs\n",
    "    #data_internal=data\n",
    "    combined_data = np.concatenate((data, exogenous_inputs),axis=2)\n",
    "    df_scaled_interal=df_scaled\n",
    "    # Number of time steps we can predict using rolling windows\n",
    "    num_samples = len(data) - window_size\n",
    "    print(combined_data.shape)\n",
    "    for i in range(num_samples):\n",
    "        # Extract the input window (input for the model)\n",
    "        #input_window = combined_data[i:i+window_size]\n",
    "        \n",
    "        # Reshape to match model input shape (batch_size, window_size, n_features)\n",
    "        #input_window = np.expand_dims(input_window, axis=0)  # Add batch dimension\n",
    "        #print(input_window.shape)\n",
    "        # Get the prediction (the output is a sequence, take the last step if forecast_steps > 1)\n",
    "        #prediction = model.predict(input_window)\n",
    "        prediction = model.predict(combined_data[i,:,:].reshape(1,10,3), verbose=False)\n",
    "        \n",
    "        # Append prediction\n",
    "        predictions.append(prediction[0][-1] if forecast_steps > 1 else prediction[0])\n",
    "        print(\"what you need is\",df_scaled_interal.iloc[i+1+window_size])\n",
    "        print(\"df_scaled_interal shape pre\",df_scaled_interal.shape)\n",
    "        if i>=train_test_split:\n",
    "            df_scaled_interal.iloc[i+1+window_size] = prediction        \n",
    "            print(\"df_scaled_interal shape post\",df_scaled_interal.shape)\n",
    "        data_internal,_  = prepare_forecat_data(df_scaled_interal, input_window=10, output_window=1, target=['Passengers']) \n",
    "        print(data_internal.shape, exogenous_inputs.shape)\n",
    "\n",
    "        combined_data = np.concatenate((data_internal, exogenous_inputs),axis=2)  \n",
    "        print(combined_data.shape)\n",
    "        \n",
    "    return np.array(predictions)\n",
    "\n",
    "exogenous_inputs = X[:,:,[1,2]]\n",
    "data = X[:,:,0]\n",
    "#Define window size and forecast steps\n",
    "window_size = 10\n",
    "forecast_steps = 1\n",
    "\n",
    "predictions = rolling_window_prediction(model, data, exogenous_inputs,df_scaled, window_size, forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out training and testing errors\n",
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scaling for predictions\n",
    "def inverse_scale(scaler, predictions, target_index):\n",
    "    # Inverse scale only the target column\n",
    "    full_scaled = np.zeros((len(predictions), scaler.n_features_in_))\n",
    "    full_scaled[:, target_index] = predictions.flatten()\n",
    "    return scaler.inverse_transform(full_scaled)[:, target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Passengers'\n",
    "target_index = list(airpass.columns).index(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape,airpass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = inverse_scale(scaler, predictions, 0)[0:train_test_split]\n",
    "test_predict = inverse_scale(scaler, predictions, 0)[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot everything - the original series as well as predictions on training and testing sets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot original series\n",
    "plt.plot(airpass['Passengers'].iloc[:134],color = 'g')\n",
    "\n",
    "# plot training set prediction\n",
    "split_pt = train_test_split + window_size \n",
    "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
    "\n",
    "# plot testing set prediction\n",
    "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
    "\n",
    "# pretty up graph\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('(normalized) price of Apple stock')\n",
    "plt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you can try out any time series for this exercise!  If you would like to try another see e.g., [this site containing thousands of time series](https://datamarket.com/data/list/?q=provider%3Atsdl) and pick another one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "train_mape = mean_absolute_percentage_error(airpass['Passengers'][10:100], train_predict) \n",
    "test_mape = mean_absolute_percentage_error(airpass['Passengers'][100:134], test_predict) \n",
    "print(f'MAPE on Train data is: { round(train_mape*100,1)} %')\n",
    "print(f'MAPE on Test data is: { round(test_mape*100,1)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "TF_python310",
   "language": "python",
   "name": "tf_python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
